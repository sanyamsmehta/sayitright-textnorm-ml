{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIMlQ9oTqaRt"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets\n",
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m_2oVlOfXY9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical  # Import for converting categorical labels\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "from datasets import Dataset, load_metric\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6NlwE5Cfm58"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "df = pd.read_excel(\"en_train_updated.xlsx\")\n",
        "df = df.head(2000000)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O52lm-kk6dF"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "df['before'] = df['before'].astype('str')\n",
        "df['class'] = df['class'].astype('str')\n",
        "df['after'] = df['after'].astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xeo8gz-ifm8p"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "df = df[['class', 'before', 'after']]\n",
        "dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alVujAq6nQXP"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset.train_test_split(test_size=0.2, seed=42)['train']\n",
        "test_dataset = dataset.train_test_split(test_size=0.2, seed=42)['test']\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "metric = load_metric(\"sacrebleu\")\n",
        "\n",
        "def data_collator(examples):\n",
        "    inputs = [f\"convert: {example['class']} {example['before']} => \" for example in examples]\n",
        "    targets = [example['after'] for example in examples]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=512, truncation=True, padding=True, return_tensors='pt')\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gVmJOipv-9b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred, labels):\n",
        "    pred_ids = pred.logits.argmax(-1)\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Convert labels tensor to list of strings\n",
        "    labels_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Convert labels to list of lists\n",
        "    labels_str = [[token] for token in labels_str]\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    sacrebleu = metric.compute(predictions=pred_str, references=labels_str)[\"score\"]\n",
        "\n",
        "    return {\"accuracy\": sacrebleu}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm4uvWpLnlPk"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "txqwDozYn0v1"
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=data_collator)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_accuracy = 0\n",
        "    for batch in train_loader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "        train_accuracy += compute_metrics(outputs, batch[\"labels\"])[\"accuracy\"]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    train_loss /= len(train_loader)\n",
        "    train_accuracy /= len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        test_accuracy = 0\n",
        "        for batch in test_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            test_loss += loss.item()\n",
        "            test_accuracy += compute_metrics(outputs, batch[\"labels\"])[\"accuracy\"]\n",
        "        test_loss /= len(test_loader)\n",
        "        test_accuracy /= len(test_loader)\n",
        "        print(f\"Epoch: {epoch+1}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}\")\n",
        "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}